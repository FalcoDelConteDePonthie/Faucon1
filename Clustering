import numpy as np
import pandas as pd
import random
from sklearn import preprocessing
# This method select random initial centroid from dataset
# and memorize it in "centroidi" vector for returned it
def calcolaCentroidiRandom(data):
    centroidi = []
    i = 0
    # Finche non arrivo in posizione colonna clustering
    while i < int(Numclust):
        # Estrae il punto dal data point in modo randomico
        idx = int(int(0) + (random.random() * (int(N) - int(0))))
        i += 1
        centroidi.append(data[idx].tolist())   
    centroidi = np.array(centroidi)
    return centroidi   

# Metodo che serve per leggere il file CSV
def leggiCsv(nomeFile,separatore):
    file = pd.read_csv(nomeFile,separatore,dtype='float64')
    return file


def normalizzaDati(dati):
    min_max_scaler = preprocessing.MinMaxScaler()
    np_scaled = min_max_scaler.fit_transform(dati)
    #df_normalized = pd.DataFrame(np_scaled)
    return np_scaled


def dist(x, l): 
    dSum = 0.0	
    for j in range(0,D):
        dSum += pow(x[j] - Z[l][j], 2.0)
    return dSum

def getListPair(Numclust,dati):
    lista = pd.DataFrame(columns=list('AB')) 
    vD = []
    for i in range(0,N):
        dMin = float('inf')
        s = -1
        for j in range(0,Numclust):
            dDist = dist(dati[i],j)
            if dMin > dDist:
                dMin = dDist
                s = j
        vD.append(s)
        lista = lista.append({'A': dMin,'B': i}, ignore_index=True)
    lista = lista.sort_values(by=['A'],ascending=False)
    return lista,vD

def getOutlier(nOutliers,CM,listPair,lstcluster):
    for j in range(0,nOutliers):
        i = int(listPair.iloc[j]['B'])
        if int(CM[i]) != int(Numclust):
            lstcluster[int(CM[i])].remove(data[i].tolist())
            lstcluster[Numclust].append(data[i].tolist())          
            CM[i] = Numclust
    return lstcluster,CM


def getNotOutlier(nOutliers,CM,listPair,lstcluster,vd):
    for l in range(nOutliers,N):
        i = int(listPair.iloc[l]['B'])
        s = int(vd[i])
        if int(CM[i]) != int(s):
            lstcluster[int(CM[i])].remove(data[i].tolist())
            lstcluster[s].append(data[i].tolist())
            CM[i] = s
    return lstcluster,CM        
           
def updateU(dati,dAvgDist,lstcluster,cm):
    listPair, vd = getListPair(Numclust,dati)        
    nOutliers = 0
    for i in range(0,N0):
        if listPair.iloc[i]['A'] <= dAvgDist:
            break
        nOutliers=i+1
    
    lstcluster,cm = getOutlier(nOutliers,cm,listPair,lstcluster)
            
    lstcluster,cm = getNotOutlier(nOutliers,cm,listPair,lstcluster,vd)

    
    return lstcluster, CM 
       
       
def calculateObj(data,lstCluster,Z):    
    dSum1 = 0.0
    for i in range(0,N):
        j = CM[i]
        if j < Numclust:
            dSum1 += dist(data[i], int(j))

    dAvgDist = dSum1 * Gamma / (N - len(lstCluster[Numclust]))
    dobj = dSum1 + dAvgDist * len(lstCluster[Numclust])
    return dAvgDist, dobj  
       
def updateZ(lstcluster,Z):
    dTemp = 0.0
    for k in range(0,Numclust): 
        for j in range(0,D):
            dTemp = 0.0
            for i in range(0,len(lstcluster[k])):
                rec = lstcluster[k][i]
                dTemp += rec[j]
            if len(lstcluster[k]) != 0:
                Z[k][j] = dTemp / len(lstcluster[k])
            else:
                Z[k][j] = Z[k][j]
    return Z



# Primo Step inizializzare in modo randomico i centroidi dopo aver letto e normalizzato i dati
dati = leggiCsv("shuttle_norm.csv",";")
# Per convenzione uso la maiuscola per indicare che sono costanti
N = np.shape(dati)[0]
D = np.shape(dati)[1]    
data = normalizzaDati(dati)
print(type(data))
Gamma = 9
Delta = pow(10,-6)
Numclust = 3
Maxiter = 100
P0 = 0.1
N0 = int(P0*N)
TOT = 0
# Secondo Step per ogni centroide prendo il data point e cerco per quale dei k
# centroidi la distanza Ã¨ minore. A quello assegno il punto
for i in range(0,1):
    CM = []
    CM = np.array(CM, dtype="float64")
    Z = []
    Z = np.array(Z, dtype="float64")
    Z =  calcolaCentroidiRandom(data)
    Z = [[0.282828283, 0.487570736, 0.4921875, 0.50701506, 0.387820513, 0.51280246, 0.503267974, 0.614767255, 0.575562701],
         [0.101010101, 0.486661277, 0.4296875, 0.50701506, 0.362179487, 0.513247119, 0.568627451, 0.62600321, 0.572347267],
         [0.101010101, 0.487166532, 0.4609375, 0.50701506, 0.346153846, 0.513284174, 0.594771242, 0.650080257, 0.585209003]]
    print(Z)
    lstCluster = []
    for i in range(0,Numclust+1):
        app = []
        lstCluster.append(app)
    s = -1
    for i in range(0,N):
        dMin = float('inf')
        s=-1
        for j in range(0,Numclust):
            dDist = dist(data[i],j)
            if dDist < dMin:
                s = j
                dMin = dDist
        lstCluster[s].append(data[i].tolist())
        CM = np.append (CM, s)

    dAvgDist, dobj = calculateObj(data,lstCluster,Z)
    numiter = 1
    while(1==1):	
        lstCluster, CM = updateU(data,dAvgDist,lstCluster,CM)
        Z = updateZ(lstCluster,Z)
        dObjPre = dobj
        dAvgDist, dobj = calculateObj(data,lstCluster,Z)
        if abs(dObjPre - dobj) < Delta:
            break
        numiter+=1
        if numiter > Maxiter:
            break
        print(len(lstCluster[-1]))
        
print("##########OUTLIER############")
print(len(lstCluster[-1]))
print("##########BUONI############")
print(len(lstCluster[0]))
print("####")
print(len(lstCluster[1]))
print("####")
print(len(lstCluster[2]))
print("####")
#print(TOT/100)
